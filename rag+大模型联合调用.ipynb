{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c9038f5-46a3-47ec-a3ab-786482b383de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asycn_model_tool import Qwen\n",
    "import asyncio\n",
    "from rag import RAG,VectorStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83bc0d2a-10e4-4d4e-ad50-703c34248b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 15:32:20,259 - asycn_model_tool - INFO - 正在初始化 Qwen 模型...\n",
      "2025-03-09 15:32:20,495 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112436476c124ce6a6fa13a1f035ecb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 15:32:23,360 - asycn_model_tool - INFO - Qwen 模型初始化完成\n",
      "2025-03-09 15:32:23,362 - asycn_model_tool - INFO - 批处理循环已启动\n",
      "2025-03-09 15:32:23,365 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: shibing624/text2vec-base-chinese\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已加载到 cuda 设备\n",
      "向量存储已从 ./vector_store 加载，包含 23974 个文档\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 15:32:24,133 - asycn_model_tool - INFO - 处理批次，批次大小: 1\n",
      "2025-03-09 15:32:29,892 - asycn_model_tool - INFO - 批处理生成完成，处理时间: 5.76秒，批次大小: 1\n",
      "2025-03-09 15:32:29,906 - asycn_model_tool - INFO - 处理批次，批次大小: 3\n",
      "2025-03-09 15:32:30,269 - asycn_model_tool - ERROR - 批处理循环错误: CUDA out of memory. Tried to allocate 1.78 GiB. GPU \n",
      "Traceback (most recent call last):\n",
      "  File \"/root/autodl-tmp/asycn_model_tool.py\", line 186, in _batch_process_loop\n",
      "    results = await self._process_batch(batch)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/autodl-tmp/asycn_model_tool.py\", line 241, in _process_batch\n",
      "    generated_ids = self.model.generate(**batch_inputs, **self.generation_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py\", line 2228, in generate\n",
      "    result = self._sample(\n",
      "             ^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py\", line 3209, in _sample\n",
      "    outputs = self(**model_inputs, return_dict=True)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py\", line 1822, in forward\n",
      "    logits = self.lm_head(hidden_states)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/miniconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 116, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.78 GiB. GPU \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "初始化模型、读取向量文档\n",
    "'''\n",
    "\n",
    "\n",
    "model=Qwen();\n",
    "await model.start()\n",
    "\n",
    "model_cache_dir = \"./models\"\n",
    "save_dir = \"./vector_store\"\n",
    "\n",
    "\n",
    "vector_store = VectorStore.load(\n",
    "            save_dir=save_dir,\n",
    "            embedding_model='shibing624/text2vec-base-chinese',\n",
    "            model_cache_dir=model_cache_dir,\n",
    "            device='cuda'\n",
    "        )\n",
    "\n",
    "rag = RAG(vector_store)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9090aef2-bb4d-4244-993e-b41f41dae5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7783293dba4b03a16f7868e41da36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是我所查到的文档:\n",
      "文档 1 (相似度: 256.1937):\n",
      "【user】: 这是一个在2022/1/1百家号发布的新闻。标题是匿名黑客Deric Lostutter面临16年监禁，而Steubenville强奸犯逍遥法外，正文是2016年9月14日 · 哼，我不管，Lostutter就是无罪不合理：曝光强奸犯的黑客可能比强奸犯本人面临更多监禁一条里根时代的网络安全法可以判定Deric Lostutter入狱16年。 一名黑客发现两个男人强暴一个无意识的16岁少女 …，是属于类别的新闻。[图片: images/blank.jpg]请你告诉我是否是谣言。\n",
      "\n",
      "【assistant】: 谣言\n",
      "\n",
      "\n",
      "\n",
      "文档 2 (相似度: 201.9139):\n",
      "【user】: 这是一个在2020/1/16Taiwan FactCheck Center发布的新闻。标题是反分裂法／反渗透法 1/15生效，选举的PO文不分蓝绿，请全部删掉以免惹事生非。1/16就会开始执行，正文是无内容，是属于类别的新闻。[图片: images/blank.jpg]请你告诉我是否是谣言。\n",
      "\n",
      "【assistant】: 谣言\n",
      "\n",
      "\n",
      "\n",
      "文档 3 (相似度: 199.7449):\n",
      "【user】: 这是一个在2017/10/26mygopen发布的新闻。标题是注意!!帐号姓名:崔瑞恩？骇客？要小心一封为「来抽支签！」的档案？谣言别再传了，正文是无内容，是属于类别的新闻。[图片: images/blank.jpg]请你告诉我是否是谣言。\n",
      "\n",
      "【assistant】: 谣言\n",
      "\n",
      "这是一个在2022/1/1百家号发布的新闻。标题是匿名黑客Deric Lostutter面临16年监禁，而Steubenville强奸犯逍遥法外，正文是2016年9月14日 · 哼，我不管，Lostutter就是无罪不合理：曝光强奸犯的黑客可能比强奸犯本人面临更多监禁一条里根时代的网络安全法可以判定Deric Lostutter入狱16年。 一名黑客发现两个男人强暴一个无意识的16岁少女 …，是属于类别的新闻。请你告诉我是否是谣言。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574df07f779e4ba6977dc0e271047b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是我所查到的文档:\n",
      "文档 1 (相似度: 256.1937):\n",
      "【user】: 这是一个在2022/1/1百家号发布的新闻。标题是匿名黑客Deric Lostutter面临16年监禁，而Steubenville强奸犯逍遥法外，正文是2016年9月14日 · 哼，我不管，Lostutter就是无罪不合理：曝光强奸犯的黑客可能比强奸犯本人面临更多监禁一条里根时代的网络安全法可以判定Deric Lostutter入狱16年。 一名黑客发现两个男人强暴一个无意识的16岁少女 …，是属于类别的新闻。[图片: images/blank.jpg]请你告诉我是否是谣言。\n",
      "\n",
      "【assistant】: 谣言\n",
      "\n",
      "\n",
      "\n",
      "文档 2 (相似度: 201.9139):\n",
      "【user】: 这是一个在2020/1/16Taiwan FactCheck Center发布的新闻。标题是反分裂法／反渗透法 1/15生效，选举的PO文不分蓝绿，请全部删掉以免惹事生非。1/16就会开始执行，正文是无内容，是属于类别的新闻。[图片: images/blank.jpg]请你告诉我是否是谣言。\n",
      "\n",
      "【assistant】: 谣言\n",
      "\n",
      "\n",
      "\n",
      "文档 3 (相似度: 199.7449):\n",
      "【user】: 这是一个在2017/10/26mygopen发布的新闻。标题是注意!!帐号姓名:崔瑞恩？骇客？要小心一封为「来抽支签！」的档案？谣言别再传了，正文是无内容，是属于类别的新闻。[图片: images/blank.jpg]请你告诉我是否是谣言。\n",
      "\n",
      "【assistant】: 谣言\n",
      "\n",
      "这是一个在2022/1/1百家号发布的新闻。标题是匿名黑客Deric Lostutter面临16年监禁，而Steubenville强奸犯逍遥法外，正文是2016年9月14日 · 哼，我不管，Lostutter就是无罪不合理：曝光强奸犯的黑客可能比强奸犯本人面临更多监禁一条里根时代的网络安全法可以判定Deric Lostutter入狱16年。 一名黑客发现两个男人强暴一个无意识的16岁少女 …，是属于类别的新闻。请你告诉我是否是谣言。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef0fc78c8f84c0b923f3c9439183bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是我所查到的文档:\n",
      "文档 1 (相似度: 256.1937):\n",
      "【user】: 这是一个在2022/1/1百家号发布的新闻。标题是匿名黑客Deric Lostutter面临16年监禁，而Steubenville强奸犯逍遥法外，正文是2016年9月14日 · 哼，我不管，Lostutter就是无罪不合理：曝光强奸犯的黑客可能比强奸犯本人面临更多监禁一条里根时代的网络安全法可以判定Deric Lostutter入狱16年。 一名黑客发现两个男人强暴一个无意识的16岁少女 …，是属于类别的新闻。[图片: images/blank.jpg]请你告诉我是否是谣言。\n",
      "\n",
      "【assistant】: 谣言\n",
      "\n",
      "\n",
      "\n",
      "文档 2 (相似度: 201.9139):\n",
      "【user】: 这是一个在2020/1/16Taiwan FactCheck Center发布的新闻。标题是反分裂法／反渗透法 1/15生效，选举的PO文不分蓝绿，请全部删掉以免惹事生非。1/16就会开始执行，正文是无内容，是属于类别的新闻。[图片: images/blank.jpg]请你告诉我是否是谣言。\n",
      "\n",
      "【assistant】: 谣言\n",
      "\n",
      "\n",
      "\n",
      "文档 3 (相似度: 199.7449):\n",
      "【user】: 这是一个在2017/10/26mygopen发布的新闻。标题是注意!!帐号姓名:崔瑞恩？骇客？要小心一封为「来抽支签！」的档案？谣言别再传了，正文是无内容，是属于类别的新闻。[图片: images/blank.jpg]请你告诉我是否是谣言。\n",
      "\n",
      "【assistant】: 谣言\n",
      "\n",
      "这是一个在2022/1/1百家号发布的新闻。标题是匿名黑客Deric Lostutter面临16年监禁，而Steubenville强奸犯逍遥法外，正文是2016年9月14日 · 哼，我不管，Lostutter就是无罪不合理：曝光强奸犯的黑客可能比强奸犯本人面临更多监禁一条里根时代的网络安全法可以判定Deric Lostutter入狱16年。 一名黑客发现两个男人强暴一个无意识的16岁少女 …，是属于类别的新闻。请你告诉我是否是谣言。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d42c949a24c41d18b4deed754367e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是我所查到的文档:\n",
      "文档 1 (相似度: 256.1937):\n",
      "【user】: 这是一个在2022/1/1百家号发布的新闻。标题是匿名黑客Deric Lostutter面临16年监禁，而Steubenville强奸犯逍遥法外，正文是2016年9月14日 · 哼，我不管，Lostutter就是无罪不合理：曝光强奸犯的黑客可能比强奸犯本人面临更多监禁一条里根时代的网络安全法可以判定Deric Lostutter入狱16年。 一名黑客发现两个男人强暴一个无意识的16岁少女 …，是属于类别的新闻。[图片: images/blank.jpg]请你告诉我是否是谣言。\n",
      "\n",
      "【assistant】: 谣言\n",
      "\n",
      "\n",
      "\n",
      "文档 2 (相似度: 201.9139):\n",
      "【user】: 这是一个在2020/1/16Taiwan FactCheck Center发布的新闻。标题是反分裂法／反渗透法 1/15生效，选举的PO文不分蓝绿，请全部删掉以免惹事生非。1/16就会开始执行，正文是无内容，是属于类别的新闻。[图片: images/blank.jpg]请你告诉我是否是谣言。\n",
      "\n",
      "【assistant】: 谣言\n",
      "\n",
      "\n",
      "\n",
      "文档 3 (相似度: 199.7449):\n",
      "【user】: 这是一个在2017/10/26mygopen发布的新闻。标题是注意!!帐号姓名:崔瑞恩？骇客？要小心一封为「来抽支签！」的档案？谣言别再传了，正文是无内容，是属于类别的新闻。[图片: images/blank.jpg]请你告诉我是否是谣言。\n",
      "\n",
      "【assistant】: 谣言\n",
      "\n",
      "这是一个在2022/1/1百家号发布的新闻。标题是匿名黑客Deric Lostutter面临16年监禁，而Steubenville强奸犯逍遥法外，正文是2016年9月14日 · 哼，我不管，Lostutter就是无罪不合理：曝光强奸犯的黑客可能比强奸犯本人面临更多监禁一条里根时代的网络安全法可以判定Deric Lostutter入狱16年。 一名黑客发现两个男人强暴一个无意识的16岁少女 …，是属于类别的新闻。请你告诉我是否是谣言。\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.78 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[1;32m     16\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [model\u001b[38;5;241m.\u001b[39mpredict(text, img) \u001b[38;5;28;01mfor\u001b[39;00m text, img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(texts, images)]\n\u001b[0;32m---> 18\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 处理结果\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "File \u001b[0;32m~/autodl-tmp/asycn_model_tool.py:275\u001b[0m, in \u001b[0;36mQwen.predict\u001b[0;34m(self, text, path_to_image)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_queue\u001b[38;5;241m.\u001b[39mput((future, data))\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# 等待结果\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/autodl-tmp/asycn_model_tool.py:186\u001b[0m, in \u001b[0;36mQwen._batch_process_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# 处理批次\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m处理批次，批次大小: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 186\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_batch(batch)\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# 设置结果\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(future_list):\n",
      "File \u001b[0;32m~/autodl-tmp/asycn_model_tool.py:241\u001b[0m, in \u001b[0;36mQwen._process_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    238\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[0;32m--> 241\u001b[0m     generated_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    244\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m批处理生成完成，处理时间: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m秒，批次大小: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:2228\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2220\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2221\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2222\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2223\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2224\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2225\u001b[0m     )\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2228\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2238\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2239\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2240\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2241\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2242\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2247\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2248\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/generation/utils.py:3209\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3206\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[0;32m-> 3209\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3210\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py:1822\u001b[0m, in \u001b[0;36mQwen2_5_VLForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, pixel_values, pixel_values_videos, image_grid_thw, video_grid_thw, rope_deltas, cache_position, second_per_grid_ts)\u001b[0m\n\u001b[1;32m   1808\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1809\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1810\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1818\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1819\u001b[0m )\n\u001b[1;32m   1821\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1822\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1824\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1826\u001b[0m     \u001b[38;5;66;03m# Upcast to float if we need to compute the loss to avoid potential precision issues\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.78 GiB. GPU "
     ]
    }
   ],
   "source": [
    "'''\n",
    "根据新闻文本查询数据建库\n",
    "'''\n",
    "\n",
    "text=\"这是一个在2022/1/1百家号发布的新闻。标题是匿名黑客Deric Lostutter面临16年监禁，而Steubenville强奸犯逍遥法外，正文是2016年9月14日 · 哼，我不管，Lostutter就是无罪不合理：曝光强奸犯的黑客可能比强奸犯本人面临更多监禁一条里根时代的网络安全法可以判定Deric Lostutter入狱16年。 一名黑客发现两个男人强暴一个无意识的16岁少女 …，是属于类别的新闻。请你告诉我是否是谣言。\"\n",
    "\n",
    "\n",
    "texts = [text, text, text, text]\n",
    "images = [\"blank.jpg\", \"blank.jpg\", \"blank.jpg\", \"blank.jpg\"]  \n",
    "\n",
    "\n",
    "for a in texts:\n",
    "    a=rag.generate(a)+a\n",
    "    print(a)\n",
    "\n",
    "tasks = [model.predict(text, img) for text, img in zip(texts, images)]\n",
    "\n",
    "results = await asyncio.gather(*tasks)\n",
    "\n",
    "# 处理结果\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"任务 {i+1} 结果: {result}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c0648-f3b0-4380-bb33-344564a6f4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
